{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mamba in Needle\n",
    "## A State-Space Model Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Mamba is a state-space model architecture designed to combine the high accuracy of transformers with the efficiency of linear RNNs. This report explains the key principles behind Mamba, its efficiency, scalability, and how it achieves constant time inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "- **Linear Time Training**: Unlike transformers, which scale quadratically with sequence length, Mamba optimizes training to be linear.\n",
    "- **Constant Time Inference**: Enables real-time applications by reducing computational overhead.\n",
    "\n",
    "### Scalability\n",
    "\n",
    "- **Long-Range Tasks**: Handles long sequences efficiently.\n",
    "- **Fixed Computation per Timestep**: Ensures scalability while avoiding quadratic complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter image of SSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State-Space Models\n",
    "\n",
    "The state-space model (SSM) forms the backbone of Mamba's architecture:\n",
    "\n",
    "1. **State Equation**:\n",
    "   \\[\n",
    "   h'(t) = A h(t) + B x(t)\n",
    "   \\]\n",
    "\n",
    "2. **Output Equation**:\n",
    "   \\[\n",
    "   y(t) = C h(t) + D x(t)\n",
    "   \\]\n",
    "\n",
    "\n",
    "TODO add picture!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explain mamba blocks from image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain delta, A,B,C,D matrices\n",
    "2. Simple implementation of SSM\n",
    "3. Explain the parallelism - and show how it can be implemented in parallel\n",
    "4. Final integrated loading the model \n",
    "5. Testing on ptb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add code for pscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add code to test pscan(both versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Mamba in Needle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add code snippet to instantiate mamba model, and explain hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add training code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
